{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Pytorch Tutorial </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits go to [official pytorch tutorials](http://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preface on Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a more powerful python version of [Torch](http://torch.ch/). Torch is a Scientific Computing framework, not just a Deep Learning framework, but it is famous for Deep Learning application because of its handy Neural Network library (`torch.nn`) and its executing speed. A notable drawback of Torch is its language, Lua, which we are often not familiar with. We can see Pytorch in the way as a Torch framework written in python (and many more awesome features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Torch Tensor as Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Torch and Pytorch Deep Learning regime, the main object is Tensors (multi-dimentional arrays). Pytorch wraps Tensors and the operations between them in the way that they work very similar to Numpy arrays (but can run both on CPUs and GPUs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -2  1  2]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1, -2, 1, 2]) # a numpy array\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1., -2.,  1.,  2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(x) # now x is a torch Tensor\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2., -1.])\n"
     ]
    }
   ],
   "source": [
    "y = torch.Tensor([0,1,2,-1]) # we can initialize some tensor directly from a python list\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1., -1.,  3.,  1.])\n",
      "<class 'torch.Tensor'>\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "z = x + y # normal tensor operation, the result is a Tensor\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Pytorch, tensors are initialized in a weird way, you are the ones who have to initialize it properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-14162.9453,      0.0000, -14162.9453,      0.0000],\n",
      "        [  -154.9515,      0.0000,  -1339.8203,      0.0000],\n",
      "        [     0.0000,         nan,      0.0000,      0.0000],\n",
      "        [    -0.0000,      0.0000,      0.0000,      0.0000],\n",
      "        [     0.0000,      0.0000,      0.0000,      0.0000]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n",
      "tensor([[5., 4.]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5,4) \n",
    "print(x)\n",
    "x = torch.zeros(5,4) # As default, a tensor in pytorch is a float tensor (torch.float32)\n",
    "print(x)\n",
    "x = torch.ones([5,4], dtype=torch.int64) \n",
    "print(x)\n",
    "x = torch.Tensor([[5,4]]) # Initialize it from python list \n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can access and slice Tensors like you do with numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([3., 6., 9.])\n",
      "tensor([[4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \n",
    "print(x)\n",
    "print(x[:,2])\n",
    "print(x[1:3,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `view()` to reshape Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[-14162.9141,      0.0000, -14162.9141,      0.0000,      0.0000,\n",
      "              0.0000],\n",
      "        [     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000]])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(3,4) \n",
    "print(x.shape)\n",
    "x = x.view(2,6)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pytorch Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable == Tensor (Pytorch 0.4 and later)\n",
    "In previous versions of Pytorch prior to 0.4, Tensors works as Numpy arrays but both on GPUs and CPUs, and Pytorch variables contain their data (a Tensor) and other information (essentially, a Pytorch Variable is a node in the computational graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([3])\n",
    "w = Variable(torch.Tensor([2]),requires_grad=True)\n",
    "b = Variable(torch.Tensor([3]),requires_grad=True)\n",
    "z = a * w\n",
    "y = z + b\n",
    "print(y.data) # data of a variable y is a tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables not only contain data but also how it's formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ThMulBackward object at 0x7f489ad9bef0>\n",
      "<ThAddBackward object at 0x7f489ad9bfd0>\n"
     ]
    }
   ],
   "source": [
    "print(z.grad_fn)  \n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But from Pytorch 0.4, Tensor and Variable are merged. Tensors have the same properties and methods as Variable. So now you can use Tensor instead of Variable or you can still warp Tensor in a Variable as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.])\n",
      "None\n",
      "tensor([9.], grad_fn=<ThAddBackward>)\n",
      "tensor([9.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([3]) # Normal tensor - multi array\n",
    "print(a)\n",
    "print(a.grad_fn)\n",
    "\n",
    "w = torch.Tensor([2]) # A variable - A tensor which contains other information\n",
    "w.requires_grad = True\n",
    "\n",
    "b = torch.Tensor([3])\n",
    "b.requires_grad = True\n",
    "z = a * w\n",
    "y = z + b\n",
    "print(y)\n",
    "print(y.data) # data of a variable y is a normal tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can do auto differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # y = a * w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)  \n",
    "print(w.grad) # w and b are variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(z.grad)\n",
    "print(a.grad) # z and a are normal tensors, no gradient information included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients of more complicated functions can be calculated easily: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Mean of Squared Error: 0.965555521359\n",
      "Pytorch Mean of Squared Error: tensor(0.9656, grad_fn=<DivBackward0>)\n",
      "===============================\n",
      "My Derivatives: [[-0.28325768 -0.11636305]\n",
      " [ 0.09598345  0.00208108]\n",
      " [-0.13488133 -0.06288795]\n",
      " [-0.47412889  0.36447121]]\n",
      "Pytorch Derivative: tensor([[-0.2833, -0.1164],\n",
      "        [ 0.0960,  0.0021],\n",
      "        [-0.1349, -0.0629],\n",
      "        [-0.4741,  0.3645]])\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error(t, y):  # Mean squared error in numpy\n",
    "    # t: target label\n",
    "    # y: predicted value\n",
    "    n, m = y.shape\n",
    "    return np.sum((y - t)**2) / (n * m)\n",
    "    \n",
    "def dMSE_dy(t, y): # Derivative of mean squared error w.r.t y in numpy\n",
    "    n, m = y.shape\n",
    "    return 2 * (y-t) / (n * m)\n",
    "\n",
    "def mean_squared_error_PT(t, y): # Mean squared error - Pytorch version\n",
    "    # t: target label\n",
    "    # y: predicted value\n",
    "    n, m = y.shape\n",
    "    return torch.sum((y - t)**2) / (n * m)\n",
    "\n",
    "y = np.random.randn(4,2)\n",
    "t = np.random.randn(4,2)\n",
    "\n",
    "# forward test\n",
    "my_mse = mean_squared_error(t, y)\n",
    "\n",
    "# warp y, t to be tensors/variable\n",
    "tt = torch.Tensor(t)\n",
    "yt = Variable(torch.Tensor(y),requires_grad=True)\n",
    "pt_mse = mean_squared_error_PT(tt,yt)\n",
    "\n",
    "print(\"My Mean of Squared Error: \" + str(my_mse))\n",
    "print(\"Pytorch Mean of Squared Error: \" + str(pt_mse))\n",
    "\n",
    "# backward test\n",
    "print(\"===============================\")\n",
    "my_dmse_dy = dMSE_dy(t, y)\n",
    "\n",
    "pt_mse.backward() # Pytorch will calculate it for us\n",
    "\n",
    "print(\"My Derivatives: \" + str(my_dmse_dy))\n",
    "print(\"Pytorch Derivative: \" + str(yt.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pytorch, we can do backward from a scalar variable only (e.g. some loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Prime: [[ 0.24437018  0.24998556]\n",
      " [ 0.22977959  0.15719286]\n",
      " [ 0.24750727  0.2084922 ]\n",
      " [ 0.19146435  0.18284794]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-002cf7eb1543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sigmoid Prime: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpt_sigmoid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# THIS WILL RAISE AN ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pytorch Sigmoid Prime: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "z = np.random.randn(4,2)\n",
    "z_prime = sigmoid_prime(z)\n",
    "\n",
    "zt = torch.Tensor(z)\n",
    "zt.requires_grad = True\n",
    "pt_sigmoid = torch.sigmoid(zt)\n",
    "print(\"Sigmoid Prime: \" + str(z_prime))\n",
    "\n",
    "pt_sigmoid.backward() # THIS WILL RAISE AN ERROR\n",
    "print(\"Pytorch Sigmoid Prime: \" + str(zt.grad))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Prime: [[ 0.23129314  0.24295573]\n",
      " [ 0.1749459   0.23849607]\n",
      " [ 0.24982371  0.23542608]\n",
      " [ 0.21187894  0.24196065]]\n",
      "Pytorch Sigmoid Prime: tensor([[0.2313, 0.2430],\n",
      "        [0.1749, 0.2385],\n",
      "        [0.2498, 0.2354],\n",
      "        [0.2119, 0.2420]])\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "z = np.random.randn(4,2)\n",
    "z_prime = sigmoid_prime(z)\n",
    "\n",
    "zt = torch.Tensor(z)\n",
    "zt.requires_grad = True\n",
    "pt_sigmoid = torch.sigmoid(zt)\n",
    "print(\"Sigmoid Prime: \" + str(z_prime))\n",
    "\n",
    "# This works because L = sum(all sigmoid(zt_i)) \n",
    "# => dL/dzt_i = dL/dsigmoid * dsigmoid/dzt_i = dsigmoid/dzt_i \n",
    "# (dL/dsigmoid = 1)\n",
    "pt_sigmoid.sum().backward() \n",
    "print(\"Pytorch Sigmoid Prime: \" + str(zt.grad))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pytorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1482, -1.2756, -0.2852,  0.4313, -1.4436],\n",
      "        [-0.6384, -0.7230, -0.0108, -1.1022,  0.1441]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(2,5), requires_grad=True)\n",
    "print (x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(5, 3) # a linear transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0513, -0.8082, -0.1712],\n",
      "        [ 0.0965, -0.3425,  0.2972]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = lin(x) # forward the data x to the linear transformation\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SigmoidBackward object at 0x7f489ad50a58>\n"
     ]
    }
   ],
   "source": [
    "y = torch.sigmoid(z)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2611, -0.4481,  0.5561, -0.0567,  0.3528],\n",
      "        [-0.1638, -0.4053,  0.5753, -0.0717,  0.4512]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tanh(z)\n",
    "t = y.sum()\n",
    "t.backward()\n",
    "print(x.grad) # dt/dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Choose topology: How many layers, which activation functions\n",
    "* Choose error/cost/loss function\n",
    "* Choose updating/learning methods (sgd/rmsprop/adadelta/adam...)\n",
    "* Then define the architecture using the \"language\" of Pytorch: Pytorch will build the computational graph for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.0086,  0.5010,  0.5386],\n",
      "        [-0.5180, -0.3909,  0.0957]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.3856,  0.0061], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Input x, output y\n",
    "x = Variable(torch.randn(5, 3))\n",
    "y = Variable(torch.randn(5, 2))\n",
    "\n",
    "# Build a linear layer\n",
    "lin = nn.Linear(3, 2)\n",
    "print ('w: ', lin.weight)\n",
    "print ('b: ', lin.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(lin.parameters(), lr=0.01) # do updates on weights of the linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training a neural network\n",
    "\n",
    "1. Forward pass to calculate the outputs of the network\n",
    "2. Compute the loss\n",
    "3. Do the backward pass to calculate the error terms\n",
    "4. Update the weights based on the specified learning method (sgd/rmsprop/adadelta/adam...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = lin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1.181358814239502\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(z, y)\n",
    "print('loss: ', loss.data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Backward pass (and calculate the derivatives of the loss w.r.t weights of the linear layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw:  tensor([[ 0.1122, -0.0639,  1.1485],\n",
      "        [-0.6379,  0.0277, -0.3455]])\n",
      "dL/db:  tensor([ 1.0297, -0.1100])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "print ('dL/dw: ', lin.weight.grad) \n",
    "print ('dL/db: ', lin.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Update weights of the linear layer using Learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  1.1522507667541504\n",
      "w:  Parameter containing:\n",
      "tensor([[-0.0097,  0.5017,  0.5271],\n",
      "        [-0.5116, -0.3912,  0.0991]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.3959,  0.0072], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# update weights one time\n",
    "optimizer.step()\n",
    "\n",
    "# Equal to:\n",
    "# lin.weight.data.sub_(0.01 * lin.weight.grad.data)  (w = w - 0.01 * dloss/dw)\n",
    "# lin.bias.data.sub_(0.01 * lin.bias.grad.data)  (bias = bias - 0.01 * dloss/dbias)\n",
    "\n",
    "# Print out the loss after optimization.\n",
    "z = lin(x)\n",
    "loss = criterion(z, y)\n",
    "print('loss after 1 step optimization: ', loss.data.item()) # The loss should be smalller than in the step 2 above\n",
    "# Those weights should be changed\n",
    "print ('w: ', lin.weight)\n",
    "print ('b: ', lin.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Custom Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time we want to create our neural architecture ourself from the basic blocks of pytorch. Two things we have to do: inherit `nn.Module` and override the `__init__()` and `forward()` methods (You also have to override `backward()` method if you create the architecture based on a new activation function which hasn't been implemented in pytorch before - this is out of the scope of this tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 0.6959120035171509\n",
      "Epoch 2: Loss: 0.6953508257865906\n",
      "Epoch 3: Loss: 0.694790780544281\n",
      "Epoch 4: Loss: 0.6942321062088013\n",
      "Epoch 5: Loss: 0.6936746835708618\n",
      "Epoch 6: Loss: 0.6931184530258179\n",
      "Epoch 7: Loss: 0.692563533782959\n",
      "Epoch 8: Loss: 0.6920098662376404\n",
      "Epoch 9: Loss: 0.6914574503898621\n",
      "Epoch 10: Loss: 0.6909063458442688\n",
      "Epoch 11: Loss: 0.6903564929962158\n",
      "Epoch 12: Loss: 0.6898078918457031\n",
      "Epoch 13: Loss: 0.6892605423927307\n",
      "Epoch 14: Loss: 0.6887145042419434\n",
      "Epoch 15: Loss: 0.6881697177886963\n",
      "Epoch 16: Loss: 0.6876261830329895\n",
      "Epoch 17: Loss: 0.687083899974823\n",
      "Epoch 18: Loss: 0.6865429282188416\n",
      "Epoch 19: Loss: 0.6860032677650452\n",
      "Epoch 20: Loss: 0.6854648590087891\n",
      "Epoch 21: Loss: 0.6849276423454285\n",
      "Epoch 22: Loss: 0.6843917965888977\n",
      "Epoch 23: Loss: 0.683857262134552\n",
      "Epoch 24: Loss: 0.683323860168457\n",
      "Epoch 25: Loss: 0.6827918291091919\n",
      "Epoch 26: Loss: 0.682261049747467\n",
      "Epoch 27: Loss: 0.6817315816879272\n",
      "Epoch 28: Loss: 0.6812033653259277\n",
      "Epoch 29: Loss: 0.6806764602661133\n",
      "Epoch 30: Loss: 0.6801508069038391\n",
      "Epoch 31: Loss: 0.6796264052391052\n",
      "Epoch 32: Loss: 0.6791032552719116\n",
      "Epoch 33: Loss: 0.6785814762115479\n",
      "Epoch 34: Loss: 0.6780608892440796\n",
      "Epoch 35: Loss: 0.6775415539741516\n",
      "Epoch 36: Loss: 0.6770235896110535\n",
      "Epoch 37: Loss: 0.6765068769454956\n",
      "Epoch 38: Loss: 0.675991415977478\n",
      "Epoch 39: Loss: 0.6754772663116455\n",
      "Epoch 40: Loss: 0.6749643087387085\n",
      "Epoch 41: Loss: 0.6744526624679565\n",
      "Epoch 42: Loss: 0.6739422678947449\n",
      "Epoch 43: Loss: 0.6734331846237183\n",
      "Epoch 44: Loss: 0.6729253530502319\n",
      "Epoch 45: Loss: 0.6724187731742859\n",
      "Epoch 46: Loss: 0.6719135046005249\n",
      "Epoch 47: Loss: 0.6714094877243042\n",
      "Epoch 48: Loss: 0.6709067225456238\n",
      "Epoch 49: Loss: 0.6704052090644836\n",
      "Epoch 50: Loss: 0.669904887676239\n",
      "==================\n",
      "Apply on new data:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Result:\n",
      "tensor([[0.4756, 0.4635],\n",
      "        [0.4756, 0.4635],\n",
      "        [0.4756, 0.4635],\n",
      "        [0.4756, 0.4635],\n",
      "        [0.4756, 0.4635]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Build a sigmoid layer\n",
    "class MySigmoid(nn.Module): # inheriting from nn.Module!\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        # just inherit the init of the module\n",
    "        super(MySigmoid, self).__init__()\n",
    "        \n",
    "        # Your lego building here\n",
    "        # NOTE: The non-linearity sigmoid doesn't have any parameter so we do not put it here\n",
    "        # the layer's parameters will be all parameters from learnable modules building the layer\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through the sigmoid.\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "    \n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Input x, output y, test on t\n",
    "x = Variable(torch.randn(5, 3))\n",
    "y = Variable(torch.randn(5, 2))\n",
    "t = Variable(torch.zeros(5, 3))\n",
    "# WHAT WILL HAPPEN IF WE DO THE FOLLOWING??? TRY IT YOURSELF!!!\n",
    "#x = Variable(torch.Tensor(5,3))\n",
    "#y = Variable(torch.Tensor(5,2))\n",
    "#t = Variable(torch.Tensor(5,3)) \n",
    "\n",
    "# Create the network comprise of only that sigmoid layer\n",
    "model = MySigmoid(3,2)\n",
    "\n",
    "# Define loss and learning method\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train many times\n",
    "def train(x, y, epoch):\n",
    "    # Forward pass is different from train to test (e.g. dropout, batch norm)\n",
    "    # So it's a good habit if you explicitly speak out\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        # Pytorch accumulates gradients.  We need to clear them out before a new batch\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Forward pass and calculate errors\n",
    "        z = model(x) # This is a shortcut for calling model.forward(x)\n",
    "        loss = criterion(z, y)  # This is a shortcut for calling criterion.forward(z, y)\n",
    "        print('Epoch {}: Loss: {}'.format(i+1, loss.data.item()))\n",
    "              \n",
    "        # Do backward pass and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Test\n",
    "def test(t):\n",
    "    # Say that we do testing\n",
    "    model.eval()\n",
    "    return model(t) # Do the forward pass on the new input\n",
    "\n",
    "train(x, y, 50)\n",
    "\n",
    "# Do the test:\n",
    "print(\"==================\")\n",
    "print(\"Apply on new data:\")\n",
    "print(t.data)\n",
    "print(\"Result:\")\n",
    "print(test(t).data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Using Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[torchvision](http://pytorch.org/docs/master/torchvision/datasets.html) package (not a default pytorch package) contains popular datasets and tools to work easier with datasets, especially computer vision ones. You have to install it with conda or pip separately. Here is the example to load MNIST data and feed to a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Download MNIST traing data to directory ../Data for the first time\n",
    "# Read the training dataset from directory ../Data if there was such data\n",
    "# Convert data to Tensor and do normalization (mean, std)\n",
    "# transforms.Compose: compose of many image transformations\n",
    "mnist = datasets.MNIST(root='../Data',\n",
    "                       train=True,\n",
    "                       download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1,), (0.4,))])\n",
    "                      )\n",
    "\n",
    "# Examine data: select one data pair (the first data instance)\n",
    "image, label = mnist[0]\n",
    "print (image.size())\n",
    "print (label)\n",
    "\n",
    "# Use DataLoader to easily divide a dataset into train/valid/test with mini-batches and shuffle...\n",
    "train_loader = torch.utils.data.DataLoader(mnist, batch_size=32, shuffle=True)\n",
    "\n",
    "# Actual usage of data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Your training code will be written here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with provided datasets of the Praktikum projects, you should know how to preprocess data. The best way is to make a custom dataset and utilize DataLoader for your code. Here is the example to create a MNIST Dataset from a csv file exactly to what we have for the Neuronale Netze course. Similar to custom module, we have to inherit `Dataset` object and override `__len__()` and `__getitem__()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyMNIST(Dataset):\n",
    "    \"\"\"My custom MNIST dataset.\"\"\"\n",
    "    \n",
    "    TRAIN = 0\n",
    "    VALID = 1\n",
    "    TEST = 2\n",
    "\n",
    "    def __init__(self, csv_file, data=TRAIN, one_hot=False, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file\n",
    "            root_dir (string): Directory with all the images.\n",
    "            one_hot (boolean): Do the one-hot encoding on the labels or not\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        # load from csv_file (full path)\n",
    "        all_data = np.genfromtxt(csv_file, delimiter=\",\", dtype=\"uint8\")\n",
    "    \n",
    "        # There are 5000 instances (5000 lines in csv file)\n",
    "        # First 3000 lines will be training set\n",
    "        # The next 1000 lines will be validation set\n",
    "        # The last 1000 lines will be the test set\n",
    "        # You can modify this\n",
    "        train, test = all_data[:4000], all_data[4000:]\n",
    "        train, valid = train[:3000], train[3000:]\n",
    "        \n",
    "        # We can implement the shuffle easily as follows, \n",
    "        # but we would like to use this utility from DataLoader\n",
    "        # from numpy.random import shuffle\n",
    "        # shuffle(train)\n",
    "        # ...\n",
    "        \n",
    " \n",
    "        # The label of the digits is always the first fields\n",
    "        if data == self.TRAIN:\n",
    "            self.input = train[:, 1:]\n",
    "            self.label = train[:, 0]\n",
    "        elif data == self.VALID:\n",
    "            self.input = valid[:, 1:]\n",
    "            self.label = valid[:, 0]\n",
    "        else:\n",
    "            self.input = test[:, 1:]\n",
    "            self.label = test[:, 0]\n",
    "    \n",
    "        \n",
    "        # One-hot encoding:\n",
    "        if one_hot:\n",
    "            self.label = np.array(map(one_hot_encoding, self.label))\n",
    "           \n",
    "        # Apply the transformations:\n",
    "        for i, transfunction in enumerate(transforms):\n",
    "            self = transfunction(self)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input[idx], self.label[idx]\n",
    "\n",
    "\n",
    "# One-hot encoding\n",
    "def one_hot_encoding(idx):\n",
    "    one_hot_array = np.zeros(10)\n",
    "    one_hot_array[idx] = 1\n",
    "    return one_hot_array\n",
    "\n",
    "####################################################\n",
    "# We can also implement the transformation ourselves\n",
    "\n",
    "# This normalizer only works for our MNIST data: divide the pixel values to 255\n",
    "# We can implement other general normalizers, e.g. standard normalizer, by:\n",
    "# mean = np.mean(data.input)\n",
    "# std = np.std(data.input)\n",
    "# data.input = (data.input - mean)/std\n",
    "\n",
    "class Normalizer(object):\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data.input = 1.0*data.input/255\n",
    "        return data\n",
    "\n",
    "# This convert from numpy arrays of data to pytorch tensors\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data.input = torch.from_numpy(data.input).float()\n",
    "        data.label = torch.from_numpy(data.label).long()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do similar things as the `torchvision.datasets.MNIST`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some helper function to draw the image\n",
    "def plot(img):\n",
    "    plt.imshow(img.view(28,28).numpy())\n",
    "    \n",
    "    \n",
    "my_mnist = MyMNIST(csv_file='../Data/mnist_seven.csv',\n",
    "                data=MyMNIST.TEST,\n",
    "                one_hot=False,\n",
    "                transforms=[Normalizer(),\n",
    "                            ToTensor()])\n",
    "\n",
    "\n",
    "# Examine data: select one data pair\n",
    "image, label = my_mnist[3]\n",
    "plot(image)\n",
    "print(\"Label: \" + str(label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(my_mnist, batch_size=32, shuffle=True)\n",
    "\n",
    "# Actual usage of data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Your training code will be written here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Complete example on MNIST (CPU version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can do a complete Feedforward Network to recognize handwritten digits trained and test on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/938: Loss: 1.97\n",
      "Iteration 200/938: Loss: 1.41\n",
      "Iteration 300/938: Loss: 0.93\n",
      "Iteration 400/938: Loss: 0.66\n",
      "Iteration 500/938: Loss: 0.85\n",
      "Iteration 600/938: Loss: 0.46\n",
      "Iteration 700/938: Loss: 0.72\n",
      "Iteration 800/938: Loss: 0.56\n",
      "Iteration 900/938: Loss: 0.48\n",
      "Epoch 1: Loss: 0.44727399945259094\n",
      "Iteration 100/938: Loss: 0.42\n",
      "Iteration 200/938: Loss: 0.38\n",
      "Iteration 300/938: Loss: 0.36\n",
      "Iteration 400/938: Loss: 0.35\n",
      "Iteration 500/938: Loss: 0.39\n",
      "Iteration 600/938: Loss: 0.34\n",
      "Iteration 700/938: Loss: 0.35\n",
      "Iteration 800/938: Loss: 0.40\n",
      "Iteration 900/938: Loss: 0.39\n",
      "Epoch 2: Loss: 0.21507880091667175\n",
      "Iteration 100/938: Loss: 0.36\n",
      "Iteration 200/938: Loss: 0.46\n",
      "Iteration 300/938: Loss: 0.33\n",
      "Iteration 400/938: Loss: 0.40\n",
      "Iteration 500/938: Loss: 0.21\n",
      "Iteration 600/938: Loss: 0.57\n",
      "Iteration 700/938: Loss: 0.27\n",
      "Iteration 800/938: Loss: 0.42\n",
      "Iteration 900/938: Loss: 0.12\n",
      "Epoch 3: Loss: 0.30314961075782776\n",
      "Iteration 100/938: Loss: 0.46\n",
      "Iteration 200/938: Loss: 0.21\n",
      "Iteration 300/938: Loss: 0.26\n",
      "Iteration 400/938: Loss: 0.27\n",
      "Iteration 500/938: Loss: 0.43\n",
      "Iteration 600/938: Loss: 0.42\n",
      "Iteration 700/938: Loss: 0.32\n",
      "Iteration 800/938: Loss: 0.21\n",
      "Iteration 900/938: Loss: 0.24\n",
      "Epoch 4: Loss: 0.16788595914840698\n",
      "Iteration 100/938: Loss: 0.24\n",
      "Iteration 200/938: Loss: 0.36\n",
      "Iteration 300/938: Loss: 0.25\n",
      "Iteration 400/938: Loss: 0.41\n",
      "Iteration 500/938: Loss: 0.34\n",
      "Iteration 600/938: Loss: 0.28\n",
      "Iteration 700/938: Loss: 0.30\n",
      "Iteration 800/938: Loss: 0.23\n",
      "Iteration 900/938: Loss: 0.30\n",
      "Epoch 5: Loss: 0.49949324131011963\n",
      "Accuracy on the test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define custom network: 3 layers\n",
    "class MyFNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.3):\n",
    "        super(MyFNN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential()  # Container of modules\n",
    "        \n",
    "        # Dynamically build network\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            self.model.add_module(\"linear\" + str(i+1), nn.Linear(input_size, hidden_size))\n",
    "            self.model.add_module(\"sigmoid\" + str(i+1), nn.Sigmoid())\n",
    "            self.model.add_module(\"dropout\" + str(i+1), nn.Dropout(dropout))\n",
    "            input_size = hidden_size\n",
    "        \n",
    "        self.model.add_module(\"linear\" + str(len(hidden_sizes)+1), nn.Linear(input_size, output_size, bias=False))\n",
    "        # If you use CrossEntropyLoss instead of NLLLoss, do not need to add this LogSoftmax layer\n",
    "        # self.model.add_module(\"logsoftmax\", nn.LogSoftmax())  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "    \n",
    "batch_size = 64\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Two-hidden-layer Feedforward Network with default dropout\n",
    "net = MyFNN(784, [100, 50], 10)\n",
    "\n",
    "\n",
    "#criterion = nn.NLLLoss()  # Use Negative Log Likelihood\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "def train(epoch, train_data):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        num_batch = len(train_data)//batch_size + 1\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.view(-1, 28*28)\n",
    "            \n",
    "            #Zero grads before each optimizing step\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass and calculate errors\n",
    "            y = net(images)\n",
    "            loss = criterion(y, labels)\n",
    "            if (batch_idx+1) % 100 == 0:\n",
    "                print('Iteration {0:d}/{1:d}: Loss: {2:.2f}'.format(batch_idx+1, num_batch, loss.data.item()))\n",
    "            # Do backward pass and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch {}: Loss: {}'.format(i+1, loss.data.item()))\n",
    "\n",
    "\n",
    "# Train\n",
    "from torchvision import datasets, transforms\n",
    "train_data = datasets.MNIST(root='../Data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True)\n",
    "net.train()    \n",
    "train(5, train_data)\n",
    "\n",
    "\n",
    "# Test\n",
    "test_data = datasets.MNIST(root='../Data', \n",
    "                            train=False, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0 # accumulated loss over mini-batches\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28*28)\n",
    "    y = net(images)\n",
    "    _, predicts = torch.max(y.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicts == labels).sum()\n",
    "   \n",
    "print('Accuracy on the test images: %d %%' % (100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Example on our custom MNIST data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 2.328505039215088\n",
      "Epoch 2: Loss: 2.2135486602783203\n",
      "Epoch 3: Loss: 2.198232650756836\n",
      "Epoch 4: Loss: 2.107914686203003\n",
      "Epoch 5: Loss: 2.1009528636932373\n",
      "Epoch 6: Loss: 1.8800849914550781\n",
      "Epoch 7: Loss: 1.794089913368225\n",
      "Epoch 8: Loss: 1.661250114440918\n",
      "Epoch 9: Loss: 1.52210533618927\n",
      "Epoch 10: Loss: 1.5143582820892334\n",
      "Epoch 11: Loss: 1.3810864686965942\n",
      "Epoch 12: Loss: 1.328049898147583\n",
      "Epoch 13: Loss: 1.195167899131775\n",
      "Epoch 14: Loss: 1.2042210102081299\n",
      "Epoch 15: Loss: 1.2199808359146118\n",
      "Epoch 16: Loss: 0.9485584497451782\n",
      "Epoch 17: Loss: 0.9740575551986694\n",
      "Epoch 18: Loss: 0.9747207760810852\n",
      "Epoch 19: Loss: 0.9090003967285156\n",
      "Epoch 20: Loss: 0.9006780385971069\n",
      "Epoch 21: Loss: 0.7593070864677429\n",
      "Epoch 22: Loss: 0.8389652967453003\n",
      "Epoch 23: Loss: 0.6704359650611877\n",
      "Epoch 24: Loss: 0.6427893042564392\n",
      "Epoch 25: Loss: 0.5813964605331421\n",
      "Epoch 26: Loss: 0.6004900932312012\n",
      "Epoch 27: Loss: 0.6656450033187866\n",
      "Epoch 28: Loss: 0.6000130772590637\n",
      "Epoch 29: Loss: 0.5313893556594849\n",
      "Epoch 30: Loss: 0.46337729692459106\n",
      "Epoch 31: Loss: 0.607324481010437\n",
      "Epoch 32: Loss: 0.36928659677505493\n",
      "Epoch 33: Loss: 0.3603079319000244\n",
      "Epoch 34: Loss: 0.46134042739868164\n",
      "Epoch 35: Loss: 0.5150289535522461\n",
      "Accuracy on the test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define custom network: 3 layerstorch.max\n",
    "class MyFNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.3):\n",
    "        super(MyFNN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential()  # Container of modules\n",
    "        \n",
    "        # Dynamically build network\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            self.model.add_module(\"linear\" + str(i+1), nn.Linear(input_size, hidden_size))\n",
    "            self.model.add_module(\"sigmoid\" + str(i+1), nn.Sigmoid())\n",
    "            self.model.add_module(\"dropout\" + str(i+1), nn.Dropout(dropout))\n",
    "            input_size = hidden_size\n",
    "        \n",
    "        self.model.add_module(\"linear\" + str(len(hidden_sizes)+1), nn.Linear(input_size, output_size, bias=False))\n",
    "        # If you use CrossEntropyLoss instead of NLLLoss, do not need to add this LogSoftmax layer\n",
    "        # self.model.add_module(\"logsoftmax\", nn.LogSoftmax())  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1234)\n",
    "    \n",
    "# Two-hidden-layer Feedforward Network with default dropout\n",
    "net = MyFNN(784, [100, 50], 10)\n",
    "\n",
    "\n",
    "#criterion = nn.NLLLoss()  # Use Negative Log Likelihood\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "def train(epoch, train_data):\n",
    "    train_loader = torch.utils.data.DataLoader(my_mnist, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        num_batch = len(train_data)//batch_size + 1\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.view(-1, 28*28)\n",
    "            \n",
    "            #Zero grads before each optimizing step\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass and calculate errors\n",
    "            y = net(images)\n",
    "            loss = criterion(y, labels)\n",
    "            if (batch_idx+1) % 100 == 0:\n",
    "                print('Iteration {0:d}/{1:d}: Loss: {2:.2f}'.format(batch_idx+1, num_batch, loss.data.item()))\n",
    "            # Do backward pass and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch {}: Loss: {}'.format(i+1, loss.data.item()))\n",
    "\n",
    "\n",
    "# Train\n",
    "from torchvision import transforms\n",
    "train_data = MyMNIST(csv_file='../Data/mnist_seven.csv',\n",
    "                    data=MyMNIST.TRAIN,\n",
    "                    one_hot=False,\n",
    "                    transforms=[Normalizer(),\n",
    "                                ToTensor()])\n",
    "\n",
    "\n",
    "net.train()    \n",
    "train(35, train_data)\n",
    "\n",
    "\n",
    "# Test\n",
    "test_data = MyMNIST(csv_file='../Data/mnist_seven.csv',\n",
    "                    data=MyMNIST.TEST,\n",
    "                    one_hot=False,\n",
    "                    transforms=[Normalizer(),\n",
    "                                ToTensor()])\n",
    "\n",
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0 # accumulated loss over mini-batches\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28*28)\n",
    "    y = net(images)\n",
    "    _, predicts = torch.max(y.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicts == labels).sum()\n",
    "   \n",
    "print('Accuracy on the test images: %d %%' % (100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Use GPUs\n",
    "Tensors stored in CPUs are different to tensors stored in GPUs. Depending on the device (currently Pytorch supports only CPUs and CUDA-enable GPUs) that tensors are stored and preprocessed differently, but in general, Pytorch wraps other operations to be transparent to the device as much as possible.  \n",
    "The following cell can be run only when you run it on a GPU-enabled device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')     # Default CUDA-enable GPU device\n",
    "cuda1 = torch.device('cuda:1')  # The second available GPU device (0-indexed)\n",
    "\n",
    "a = torch.tensor([1., 2.], device=cuda)\n",
    "print(a)\n",
    "\n",
    "b = torch.tensor([1., 2.])\n",
    "print(b)\n",
    "\n",
    "b1 = b.cuda() # Convert CPU tensor to GPU tensor (and store it on the default)\n",
    "print(b1)\n",
    "\n",
    "# Convert tensor in one device to another device\n",
    "b2 = b.to(device=cuda)\n",
    "print(b2)\n",
    "\n",
    "# The following command will raise an error since a is a GPU tensor and b is a CPU tensor\n",
    "#c1 = a + b\n",
    "#print(c1)\n",
    "\n",
    "# Convert tensor in one device to another device\n",
    "c1 = a.to(device=torch.device('cpu')) + b\n",
    "print(c1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU run on our custom data\n",
    "To run on GPUs, normally we need to convert the data (training, testing) and the model (architecture) only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define custom network: 3 layerstorch.max\n",
    "class MyFNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.3):\n",
    "        super(MyFNN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential()  # Container of modules\n",
    "        \n",
    "        # Dynamically build network\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            self.model.add_module(\"linear\" + str(i+1), nn.Linear(input_size, hidden_size))\n",
    "            self.model.add_module(\"sigmoid\" + str(i+1), nn.Sigmoid())\n",
    "            self.model.add_module(\"dropout\" + str(i+1), nn.Dropout(dropout))\n",
    "            input_size = hidden_size\n",
    "        \n",
    "        self.model.add_module(\"linear\" + str(len(hidden_sizes)+1), nn.Linear(input_size, output_size, bias=False))\n",
    "        # If you use CrossEntropyLoss instead of NLLLoss, do not need to add this LogSoftmax layer\n",
    "        # self.model.add_module(\"logsoftmax\", nn.LogSoftmax())  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Two-hidden-layer Feedforward Network with default dropout\n",
    "net = MyFNN(784, [100, 50], 10).cuda()\n",
    "\n",
    "\n",
    "#criterion = nn.NLLLoss()  # Use Negative Log Likelihood\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "def train(epoch, train_data):\n",
    "    train_loader = torch.utils.data.DataLoader(my_mnist, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        num_batch = len(train_data)//batch_size + 1\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.view(-1, 28*28).cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            #Zero grads before each optimizing step\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass and calculate errors\n",
    "            y = net(images)\n",
    "            loss = criterion(y, labels)\n",
    "            if (batch_idx+1) % 100 == 0:\n",
    "                print('Iteration {0:d}/{1:d}: Loss: {2:.2f}'.format(batch_idx+1, num_batch, loss.data.item()))\n",
    "            # Do backward pass and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch {}: Loss: {}'.format(i+1, loss.data.item()))\n",
    "\n",
    "\n",
    "# Train\n",
    "from torchvision import transforms\n",
    "train_data = MyMNIST(csv_file='../Data/mnist_seven.csv',\n",
    "                    data=MyMNIST.TRAIN,\n",
    "                    one_hot=False,\n",
    "                    transforms=[Normalizer(),\n",
    "                                ToTensor()])\n",
    "\n",
    "\n",
    "net.train()    \n",
    "train(35, train_data)\n",
    "\n",
    "\n",
    "# Test\n",
    "test_data = MyMNIST(csv_file='../Data/mnist_seven.csv',\n",
    "                    data=MyMNIST.TEST,\n",
    "                    one_hot=False,\n",
    "                    transforms=[Normalizer(),\n",
    "                                ToTensor()])\n",
    "\n",
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0 # accumulated loss over mini-batches\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28*28).cuda()\n",
    "    labels = labels.cuda()\n",
    "    y = net(images)\n",
    "    _, predicts = torch.max(y.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicts == labels).sum()\n",
    "   \n",
    "print('Accuracy on the test images: %d %%' % (100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device-independent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Complete example of MNIST (run on available devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define custom network: 3 layerstorch.max\n",
    "class MyFNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.3):\n",
    "        super(MyFNN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential()  # Container of modules\n",
    "        \n",
    "        # Dynamically build network\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            self.model.add_module(\"linear\" + str(i+1), nn.Linear(input_size, hidden_size))\n",
    "            self.model.add_module(\"sigmoid\" + str(i+1), nn.Sigmoid())\n",
    "            self.model.add_module(\"dropout\" + str(i+1), nn.Dropout(dropout))\n",
    "            input_size = hidden_size\n",
    "        \n",
    "        self.model.add_module(\"linear\" + str(len(hidden_sizes)+1), nn.Linear(input_size, output_size, bias=False))\n",
    "        # If you use CrossEntropyLoss instead of NLLLoss, do not need to add this LogSoftmax layer\n",
    "        # self.model.add_module(\"logsoftmax\", nn.LogSoftmax())  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "# Get the available device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Two-hidden-layer Feedforward Network with default dropout\n",
    "net = MyFNN(784, [100, 50], 10).to(device)\n",
    "\n",
    "\n",
    "#criterion = nn.NLLLoss()  # Use Negative Log Likelihood\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch, train_data):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        num_batch = len(train_data)//batch_size + 1\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            #Zero grads before each optimizing step\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass and calculate errors\n",
    "            y = net(images)\n",
    "            loss = criterion(y, labels)\n",
    "            if (batch_idx+1) % 100 == 0:\n",
    "                print('Iteration {0:d}/{1:d}: Loss: {2:.2f}'.format(batch_idx+1, num_batch, loss.data.item()))\n",
    "            # Do backward pass and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch {}: Loss: {}'.format(i+1, loss.data.item()))\n",
    "\n",
    "\n",
    "# Train\n",
    "from torchvision import datasets, transforms\n",
    "train_data = datasets.MNIST(root='../Data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True)\n",
    "net.train()    \n",
    "train(5, train_data)\n",
    "\n",
    "\n",
    "# Test\n",
    "test_data = datasets.MNIST(root='../Data', \n",
    "                            train=False, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0 # accumulated loss over mini-batches\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28*28).to(device)\n",
    "    labels = labels.to(device)\n",
    "    y = net(images)\n",
    "    _, predicts = torch.max(y.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicts == labels).sum()\n",
    "   \n",
    "print('Accuracy on the test images: %d %%' % (100 * correct / total))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
